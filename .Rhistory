use.veg.analysis = 0,
measure = "RR",
ai = 15, # pre-intervention vegans
bi = 21+40+27+48,  # pre-intervention non-vegans
ci = 17,  # post- vegans
di = 4+29+32+35 ) # post-non-vegans
# sanity check
15/(15+21+40+27+48)
17/(17+4+29+32+35)
##### #3827 30-day VeggieChallenge 2017 (ProVeg) #####
# MM audited 2020-2-5
# Moleman 2018's Table 6:
# pre-intervention: 4% vegans
# post-intervention: 20% vegans
# hence the absurdly large point estimate
escalc_add_row( authoryear = "30-Day VeggieChallenge (ProVeg) 2017",
substudy = NA,
desired.direction = 1,
effect.measure = "log-rr",
interpretation = "Self-describing as vegan after vs. before challenge",
use.rr.analysis = 1,
use.grams.analysis = 0,
use.veg.analysis = 0,
measure = "RR",
ai = 697, # pre-intervention vegans
bi = 4727+7502+2573,  # pre-intervention non-vegans
ci = 799+1155+530+697,  # post- vegans
di = 1239+2473+4689+217+1658+2043 ) # post-non-vegans
# sanity check
( (799+1155+530+697) / (799+1155+530+697+1239+2473+4689+217+1658+2043) ) / ( 697 / (697+4727+7502+2573) )
##### #3828 10 Weeks to Vegan (Vegan Outreach) #####
# MM audited 2020-2-5
# "Food Intake" table
escalc_add_row( authoryear = "10 Weeks to Vegan (Vegan Outreach) 2018",
substudy = NA,
desired.direction = 1,
effect.measure = "log-rr",
interpretation = "Being vegan after vs. before intervention",
use.rr.analysis = 1,
use.grams.analysis = 0,
use.veg.analysis = 0,
measure = "RR",
ai = 43, # pre-intervention vegans
bi = 190+76,  # pre-intervention non-vegans
ci = 77,  # post- vegans
di = 140+92 ) # post-non-vegans
# sanity check
43/(190+76+43)
77/(140+92+77)
###### #3839 - Great Vegan Challenge (Animal Aid) #####
# MM audited 2020-2-5
# from Grassian
# measure bar heights on page 10 ("Dietary Trends Over Time")
total.px = 850  # total vertical height representing 100%
bl.vegans.px = 31  # height of vegan part of the "0 months" bar
fu.vegans.px = 240  # height of the vegan part of the "6 months" bar
N = 470 # pg 6
( bl.prop.vegan = bl.vegans.px/total.px )
( fu.prop.vegan = fu.vegans.px/total.px )
escalc_add_row( authoryear = "The Great Vegan Challenge (Animal Aid) 2016",
substudy = NA,
desired.direction = 1,
effect.measure = "log-rr",
interpretation = "Being vegan after vs. before intervention",
use.rr.analysis = 1,
use.grams.analysis = 0,
use.veg.analysis = 0,
measure = "RR",
ai = bl.prop.vegan * N, # pre-intervention vegans
bi = (1-bl.prop.vegan) * N,  # pre-intervention non-vegans
ci = fu.prop.vegan * N,  # post- vegans
di = (1-fu.prop.vegan) * N ) # post-non-vegans
##### #3840 Veganuary (Veganuary) 2014 #####
# MM audited 2020-2-5
# % staying vegan, % reducing consumption of each category
# both broken down by baseline diet
# not perfect comparison due to reporting limitations,
#  but am comparing the proportion who said they were vegan before challenge
#  to proportion saying they ate only vegan food during the challenge
# no pages in this document, but PDF has relevant stats circled
escalc_add_row( authoryear = "Veganuary (Veganuary) 2014",
substudy = NA,
desired.direction = 1,
effect.measure = "log-rr",
interpretation = "Being vegan after vs. during intervention",
use.rr.analysis = 1,
use.grams.analysis = 0,
use.veg.analysis = 0,
measure = "RR",
ai = .149 * 3325, # pre-intervention vegans
bi = (1-.149) * 3325,  # pre-intervention non-vegans
ci = 330,  # post- vegans
di = 711-330 ) # post-non-vegans
##### #3847, #3849 - Veganuary (Veganuary) 2016 #####
# MM audited 2020-2-5
# #3849 is a Fauna report, so more info available
# Table on page 3
escalc_add_row( authoryear = "Veganuary (Veganuary) 2016",
substudy = NA,
desired.direction = 1,
effect.measure = "log-rr",
interpretation = "Being vegan after vs. before intervention",
use.rr.analysis = 1,
use.grams.analysis = 0,
use.veg.analysis = 0,
measure = "RR",
ai = .19 * 20597, # pre-intervention vegans
bi = (1-.19) * 20597,  # pre-intervention non-vegans
ci = .54 * 3369,  # post- vegans
di = (1-.54) * 3369 ) # post-non-vegans
###### **#3826 Challenge 22+ (Animals Now) #####
# MM audited 2020-2-5
d = dplyr::add_row(.data = d,
authoryear = "Challenge 22+ (Animals Now) 2018",
substudy = NA,
desired.direction = 1,
effect.measure = "log-rr",
interpretation = "Being vegan after vs. before intervention",
use.rr.analysis = 1,
use.grams.analysis = 0,
use.veg.analysis = 0,
yi = 0.0739,
vi = 0.0001 )
##### #3853, #3854 - Veganuary (Veganuary) 2015 #####
# MM audited 2020-2-5
# 49% stayed vegan after six months
##### #3846 - Veganuary (Veganuary) 2017 #####
# MM audited 2020-2-5
# 67% intending to stay vegan
##### #3845 - Veganuary (Veganuary) 2018 #####
# MM audited 2020-2-5
# 62% intend to stay vegan
##### #3841 - Veganuary (Veganuary) 2019 #####
# MM audited 2020-2-5
# 47% intending to stay vegan
##### #3833, #3835 - Summer Vegan Pledge (Animal Aid) 2018 #####
# MM audited 2020-2-5
# 53% said they have remained vegan
##### #3834 Summer Vegan Pledge (Animal Aid) 2019 #####
# MM audited 2020-2-5
# 57% said they would remain vegan
# save intermediate dataset
setwd(data.dir)
write.csv(d, "data_prepped_step2.csv", row.names = FALSE)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#                                     STEP 3 - MERGE IN QUALITATIVE DATA AND PREP ANALYSIS VARIABLES                                      #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
# MM audited 2020-2-5
# read it back in
setwd(data.dir)
d = read.csv("data_prepped_step2.csv")
# how many unique studies?
length(unique(d$authoryear))
# how many point estimates?
nrow(d)
# qualitative data entered into Excel
setwd(data.dir)
# NOTE: this step breaks if cell values are hyphenated!
d2 = read_xlsx("Extracted qualitative data.xlsx", na = "NR")
# remove missing rows, used for human-readability
d2 = d2 %>% filter(!is.na(`First author last name`))
# for some reason, reads in years in an absurd format (e.g., "2018.0" as a string)
library(tidyverse)
d2$Year = str_remove(d2$Year, "[.]0")
# clean up carriage returns
d2$`Subject country` = str_replace_all(d2$`Subject country`, "[\n]" , "")
##### unique merger variable
d$unique = NA
d$unique[ is.na(d$substudy) ] = as.character(d$authoryear[ is.na(d$substudy) ])
d$unique[ !is.na(d$substudy) ] = paste( d$authoryear[ !is.na(d$substudy) ],
d$substudy[ !is.na(d$substudy) ],
sep = " ")
d$unique
# make pretty for eventual forest plot
d2$unique = NA
d2$unique[ is.na(d2$`Substudy #`) ] = paste( d2$`First author last name`[ is.na(d2$`Substudy #`) ],
d2$Year[ is.na(d2$`Substudy #`) ],
sep = " ")
d2$unique[ !is.na(d2$`Substudy #`) ] = paste( d2$`First author last name`[ !is.na(d2$`Substudy #`) ],
d2$Year[ !is.na(d2$`Substudy #`) ],
d2$`Substudy #`[ !is.na(d2$`Substudy #`) ],
sep = " ")
d2$unique
# look for IDs from effect sizes that aren't in the qualitative data spreadsheet
#  (should be none)
d$unique[ !d$unique %in% d2$unique ]
# studies in qualitative data for which we haven't entered effect sizes
# should occur only for hopeless studies (i.e., impossible to get stats)
known.hopeless = c( "Dowsett 2018",
"Diaz 2019",
"de Lanauze 2019",
"Summer Vegan Pledge (Animal Aid) 2018",
"Summer Vegan Pledge (Animal Aid) 2019",
"Veganuary (Veganuary) 2017",
"Veganuary (Veganuary) 2018",
"Veganuary (Veganuary) 2019" )
expect_equal( sort(d2$unique[ !d2$unique %in% d$unique ]), sort(known.hopeless) )
# merge them
d = merge( d,
d2,
all.x = TRUE,
by.x = "unique",
by.y = "unique" )
############################### MERGE IN SUBJECTIVELY-RATED QUALITY DATA ###############################
# MM audited 2020-2-5
setwd(data.dir)
setwd("Dual review of quality")
d3 = read.csv("subjective_data_full_prepped.csv")
# check for studies lacking entries in subjective data
# should be only high-bias challenges
d$authoryear[ !d$authoryear %in% d3$authoryear ]
# merge with main dataset
d = merge( d,
d3[ , c("authoryear", "qual.exch", "qual.sdb", "qual.gen") ],
all.x = TRUE,
by = "authoryear" )
# save intermediate dataset
setwd(data.dir)
write.csv(d, "data_prepped_step3.csv", row.names = FALSE)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#                          STEP 4 - CONVERT EFFECT SIZES TO RR SCALE                                      #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
# read it back in
# check.names = FALSE retains spaces in variable names
setwd(data.dir)
d = read.csv("data_prepped_step3.csv", check.names = FALSE)
############################### CONVERT EFFECT SIZES - to RRs ###############################
# MM audited 2020-2-5
# types of effect measures
table( d$effect.measure )
# synchronize directions so that positive is always good
d$yi[ d$desired.direction == 1 ] = abs(d$yi[ d$desired.direction == 1 ])
d$yi[ d$desired.direction == 0 ] = -abs(d$yi[ d$desired.direction == 0 ])
# init estimates on scale used for analysis
d$logRR = NA
d$varlogRR = NA
##### RRs #####
# no conversion needed, obviously
d$logRR[ d$effect.measure == "log-rr" ] = d$yi[ d$effect.measure == "log-rr" ]
d$varlogRR[ d$effect.measure == "log-rr" ] = d$vi[ d$effect.measure == "log-rr" ]
##### SMDs #####
RR.stats = d_to_logRR( smd = d$yi[ d$effect.measure == "smd" ],
smd.se = sqrt(d$vi[ d$effect.measure == "smd" ]) )
d$logRR[ d$effect.measure == "smd" ] = RR.stats$logRR
d$varlogRR[ d$effect.measure == "smd" ] = RR.stats$varlogRR
# sanity check for absurd values
round( sort( exp(d$logRR) ), 2 )
sort(sqrt(d$varlogRR))
round( sort(d$logRR/sqrt(d$varlogRR)), 2 )  # z-scores
##### Calculate Approximate CI limits for Forest Plot #####
z.crit = qnorm(.975)
d$RR.lo = exp( d$logRR - z.crit * sqrt(d$varlogRR) )
d$RR.hi = exp( d$logRR + z.crit * sqrt(d$varlogRR) )
##### Affirmative vs. Nonaffirmative #####
d$pval = 2 * ( 1 - pnorm( abs(d$logRR) / sqrt(d$varlogRR) ) )
d$affirm = d$pval < 0.05 & d$logRR > 0
table(d$affirm)
# sanity check
# fine for RMDs to be NA since those are for the grams analysis
table( is.na(d$logRR), d$effect.measure)
# don't use these for the non-main-RR analyses
d$logRR[ d$use.rr.analysis == 0 ] = NA
d$varlogRR[ d$use.rr.analysis == 0 ] = NA
d$RR.lo[ d$use.rr.analysis == 0 ] = NA
d$RR.hi[ d$use.rr.analysis == 0 ] = NA
# save intermediate dataset
setwd(data.dir)
write.csv(d, "data_prepped_step4.csv", row.names = FALSE)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#                                  STEP 5 - RECODE VARIABLES                                     #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
# read it back in
# check.names = FALSE retains spaces in variable names
setwd(data.dir)
d = read.csv("data_prepped_step4.csv", check.names = FALSE)
############################### MAKE NEW VARIABLES AND RENAME THE EXISTING ONES ###############################
# MM audited 2020-2-5
d = d %>%
rename(
# meta-information about study and article
year = Year,
title = Title,
ref = `Ref #`,
journal = `Journal/conference (if peer-reviewed)`,
other.source = `Other source (if not peer-reviewed)`,
exclude.main = `Excluded challenge`,
borderline = `Borderline inclusion`,
mm.fave = `Among MM's favorites methodologically, exclusive of small sample size`,
stats.source = `Stats source (public data, data from author, paper, hopeless)`,
# study design, intervention, and outcome variables
perc.male = `Percent male`,
country = `Subject country`,
design = Design,
n.paper = `N (total analyzed sample size in paper, combining all substudies included here)`,
x.has.text = `Intervention has text`,
x.suffer = `Intervention has specific description or images of animal suffering`,
x.has.visuals = `Intervention has visuals`,
x.pure.animals = `Intervention is purely animal welfare`,
x.suffer = `Intervention has specific description or images of animal suffering`,
x.rec = `Intervention recommendation (reduce, go vegan, go vegetarian, no request, other)`,
x.tailored = `Intervention personally tailored`,
x.min.exposed = `Total time exposed to intervention (minutes)`,
y.cat = `Outcome category (purchase or consumption)`,
y.lag.days = `Outcome time lag from intervention (days)`,
# quality variables
qual.y.prox = `Outcome proximity (intended, self-reported, actual)`,
qual.missing = `Missing data (%)`,
qual.prereg = Preregistered,
qual.public.data = `Public data`,
qual.public.code = `Public code`,
# prose
prose.x = `Intervention (X)`,
prose.control = `Control condition`,
prose.outcome = `Outcome (Y)`,
prose.population = `Population`,
prose.notes = `Notes`
)
# get rid of columns with capital letters (not used in analysis)
has.caps = tolower(names(d)) != names(d)
d = d[ , has.caps == FALSE | names(d) %in% c("logRR", "varlogRR", "RR.lo", "RR.hi") ]
############################### RECODE VARS AND MAKE NEW ONES ###############################
# MM audited 2020-2-5
##### Cast As Numeric #####
make.numeric = c("perc.male",
"x.min.exposed",
"qual.missing")
d = d %>%
mutate_at( make.numeric, as.numeric )
##### Simple Recodings #####
d$published = !is.na(d$journal)
d$y.lag.wks = d$y.lag.days/7
d$y.long.lag = d$y.lag.days >= 7
d$randomized = grepl(" RCT", d$design)  # the leading space prevents "NRCT" from counting as randomized
d$reproducible = (d$qual.prereg == "Yes") & (d$qual.public.data == "Yes")
d$x.long = d$x.min.exposed >= 5
# recode percent male as a 10-percentage point increase
d$perc.male.10 = d$perc.male/10
##### Recode Categorical Variables to Force Levels #####
library(car)
d$x.rec = recode_factor( d$x.rec,
"No request" = "a.No request",
"Reduce" = "b.Reduce",
"Go vegetarian" = "c.Go vegetarian",
"Go vegan" = "d.Go vegan",
"Mixed" = "e.Mixed")
d$qual.y.prox = dplyr::recode( d$qual.y.prox,
"Actual" = "a.Actual",
"Self-reported" = "b.Self-reported",
"Intended" = "c.Intended" )
# collapse categories
d$qual.y.prox2 = recode_factor( d$qual.y.prox,
"Actual" = "b.Actual or self-reported",
"Self-reported" = "b.Actual or self-reported",
"Intended" = "a.Intended")
library(metafor)
library(dplyr)
library(testthat)
library(readxl)
library(stringr)
library(tidypvals)
j = tidypvals::jager2014
?tidypvals
setwd("~/Desktop")
list.files()
d = read.csv("rpp_final_data.csv")
head(d)
list.files()
d = read.csv("full_data.csv")
head(d)
table(d$pval<.05)
mean(d$pval<.05)
mean(d$pval<.05 & d$D>0)
dim(d)
pnorm( -0.5 - 0)
pnorm( 0.5 - 0)
qnorm(.2)
qnorm(.49)
######################## THOUGHT EXPERIMENTS IN PAPER ########################
ceiling = function(yi,
vi,
c) {
d = data.frame( yi, vi )
zc = qnorm(c)
# P(ui < 0)
# ASSUMES POOLED ESTIMATE > 0
d$prob = pnorm( q = 0,
mean = d$yi,
sd = sqrt(d$vi) )
d$penalized = d$prob < c
# penalized variances
d$vi.star = d$vi
d$vi.star[ d$prob < c ] = pmax( d$vi[ d$prob < c ], ( d$yi[ d$prob < c ] / zc )^2 )
# plain meta-analysis
library(metafor)
( m.std = rma.uni( yi = d$yi,
vi = d$vi,
method = "DL") )
# credibility meta-analysis will have same estimate because all penalized
# penalized
# switches from significant to NS (p=0.13)
library(metafor)
( m.pen = rma.uni( yi = d$yi,
vi = d$vi.star,
method = "DL") )
res = data.frame( Method = c("Naive", "Ceiling"),
Est = c(m.std$b, m.pen$b),
Pval = c(m.std$pval, m.pen$pval ) )
print(res)
return( list( d, res ) )
}
##### Toy Example #1 #####
ceiling( yi = rep(1, 5),
vi = rep(1, 5),
c = 0.25 )
# variances don't matter, of course
ceiling( yi = rep(1, 5),
vi = c(1, .5, .2, 1.5, 3),
c = 0.25 )
##### Toy Example #2 #####
ceiling( yi = c( rep(1, 5), rep(1.5, 5) ),
vi = c( rep(1, 5), rep(5, 5) ),
c = 0.25 )
# sanity checks
pnorm(-1/sqrt(1))  # prob for unpenalized ones (should be < 0.25)
( 1 / qnorm(.25) )^2  # vi.star for penalized ones
pnorm(-1.5/sqrt(5))  # prob for penalized ones (should be > 0.25)
# unpenalized
rma.uni( yi = c( rep(1, 5), rep(1.5, 5) ),
vi = c( rep(1, 5), rep(5, 5) ),
method = "DL")
# penalized
rma.uni( yi = c( rep(1, 5), rep(1.5, 5) ),
vi = c( rep(( 1 / qnorm(.25) )^2, 5), rep(5, 5) ),
method = "DL")
# an unpenalized study (prob of "wrong direction" already > c)
yi = .1
vi = .1
c = .3
pnorm( -yi / sqrt(vi) ) > c
-yi / sqrt(vi) > qnorm(c)
pnorm( -yi / sqrt(vi) )
c
c=0.3759148
-yi / sqrt(vi)
qnorm(c)
-yi / qnorm(c)
sqrt(vi)
vi
(yi / qnorm(c))^2
# in Gelman, but also here:
# https://math.stackexchange.com/questions/2588949/posterior-distribution-for-jeffreys-prior-of-normal-distribution-with-unknown-me
actual_cred = function( yi, vi, B ) {
pnorm( yi / ( sqrt(vi)*B ) )
}
yi = .2
vi = .1
B = 1.5
x = rnorm( n = 10000,
mean = yi/B,
sd = sqrt(vi) )
mean(x > 0)
actual_cred(yi, vi, B)
##### Credibility As Function of yi #####
yi.l = as.list( seq(1, 10, .05) )
yi = unlist(yi.l)
cred.l = lapply( yi.l, FUN = function(.x) actual_cred(.x, vi, B) )
cred.vec = unlist(cred.l)
plot( yi, cred.vec )
##### Credibility As Function of vi #####
yi = .5
vi.l = as.list( seq(0, 10, .05) )
vi = unlist(vi.l)
cred.l = lapply( vi.l, FUN = function(.vi) actual_cred(yi, .vi, B) )
cred.vec = unlist(cred.l)
plot( vi, cred.vec )
1970/2
197000/500
394*2
788/40
# agrees with http://www.campbellcollaboration.org/escalc/html/EffectSizeCalculator-SMD11.php
r_to_d_ptbis = function(r, n0 = NA, n1 = NA) {
# Jacobs & Viechtbauer, Eq (5)
# note the h term is slightly different from Borenstein
# because latter assumes equal n in each group
h = ( (n0 + n1) / n0 ) + ( (n0 + n1) / n1 )
d = ( sqrt(h) * r ) / ( sqrt(1 - r^2) )
if( !is.na(n0) & !is.na(n1) ) {
N = n0 + n1
# variance of r (Borenstein pg. 41 or Jacobs & Viechtbauer, Eq. (10))
# Campbell Collaboration also uses this (http://www.campbellcollaboration.org/escalc/html/EffectSizeCalculator-SMD11.php)
Vr = ( 1 - r^2 )^2 / (N-1)
# as in Borenstein
# this is from the delta method: https://www.wolframalpha.com/input/?i=derivative+of+2r+%2F+sqrt%281-r%5E2%29+wrt+r
Vd = 4 * Vr / ( 1 - r^2 )^3
se = sqrt(Vd)
lo = d - qnorm(.975) * se
hi = d + qnorm(.975) * se
} else {
se = NA
lo = NA
hi = NA
}
return( list( d=d, se=se, lo=lo, hi=hi ) )
}
.024*100000
.01*100000
1/10000
4255/18182
13927*.3
188000*1.3
18182/244400
20000/244400
